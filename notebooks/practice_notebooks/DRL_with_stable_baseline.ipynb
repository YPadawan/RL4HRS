{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7fd80fc",
   "metadata": {},
   "source": [
    "# Getting started\n",
    "\n",
    "- Reproducing the code form the documentation:\n",
    "    - https://stable-baselines3.readthedocs.io/en/master/guide/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972961a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a100b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c62a6d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 22.5     |\n",
      "|    ep_rew_mean        | 22.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 433      |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.685   |\n",
      "|    explained_variance | 0.139    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | -3.7     |\n",
      "|    value_loss         | 27.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 24.9     |\n",
      "|    ep_rew_mean        | 24.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 445      |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.689   |\n",
      "|    explained_variance | -0.17    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | 1.65     |\n",
      "|    value_loss         | 7.62     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 25.2     |\n",
      "|    ep_rew_mean        | 25.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 300      |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 1500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.687   |\n",
      "|    explained_variance | 0.00449  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 299      |\n",
      "|    policy_loss        | 1.7      |\n",
      "|    value_loss         | 6.82     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 25.6     |\n",
      "|    ep_rew_mean        | 25.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 431      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.605   |\n",
      "|    explained_variance | 0.0217   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -16.6    |\n",
      "|    value_loss         | 427      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 27.8     |\n",
      "|    ep_rew_mean        | 27.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 432      |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.681   |\n",
      "|    explained_variance | -0.00584 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | 1.34     |\n",
      "|    value_loss         | 5.65     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 29.6     |\n",
      "|    ep_rew_mean        | 29.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 429      |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 6        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.645   |\n",
      "|    explained_variance | -0.0028  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | 1.14     |\n",
      "|    value_loss         | 5.03     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 34.3      |\n",
      "|    ep_rew_mean        | 34.3      |\n",
      "| time/                 |           |\n",
      "|    fps                | 436       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.626    |\n",
      "|    explained_variance | -0.000888 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 1.01      |\n",
      "|    value_loss         | 4.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 37.4      |\n",
      "|    ep_rew_mean        | 37.4      |\n",
      "| time/                 |           |\n",
      "|    fps                | 437       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.623    |\n",
      "|    explained_variance | -0.000546 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 1.15      |\n",
      "|    value_loss         | 3.9       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.2     |\n",
      "|    ep_rew_mean        | 41.2     |\n",
      "| time/                 |          |\n",
      "|    fps                | 439      |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.578   |\n",
      "|    explained_variance | 0.000378 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | 1.08     |\n",
      "|    value_loss         | 3.37     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 44.8     |\n",
      "|    ep_rew_mean        | 44.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.557   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | 1.05     |\n",
      "|    value_loss         | 2.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 50       |\n",
      "|    ep_rew_mean        | 50       |\n",
      "| time/                 |          |\n",
      "|    fps                | 438      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.662   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | 0.674    |\n",
      "|    value_loss         | 2.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 54.4     |\n",
      "|    ep_rew_mean        | 54.4     |\n",
      "| time/                 |          |\n",
      "|    fps                | 437      |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.521   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.568    |\n",
      "|    value_loss         | 2.02     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 57.5     |\n",
      "|    ep_rew_mean        | 57.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 442      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.527   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | 0.667    |\n",
      "|    value_loss         | 1.63     |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 60.9     |\n",
      "|    ep_rew_mean        | 60.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 440      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.553   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 0.62     |\n",
      "|    value_loss         | 1.28     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 67        |\n",
      "|    ep_rew_mean        | 67        |\n",
      "| time/                 |           |\n",
      "|    fps                | 441       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.468    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 0.596     |\n",
      "|    value_loss         | 0.985     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 71.5     |\n",
      "|    ep_rew_mean        | 71.5     |\n",
      "| time/                 |          |\n",
      "|    fps                | 441      |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.66    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.371    |\n",
      "|    value_loss         | 0.733    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 75.8     |\n",
      "|    ep_rew_mean        | 75.8     |\n",
      "| time/                 |          |\n",
      "|    fps                | 445      |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.293   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 0.265    |\n",
      "|    value_loss         | 0.513    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 79.1     |\n",
      "|    ep_rew_mean        | 79.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 449      |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 20       |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.611   |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | 0.242    |\n",
      "|    value_loss         | 0.339    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 83        |\n",
      "|    ep_rew_mean        | 83        |\n",
      "| time/                 |           |\n",
      "|    fps                | 452       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.442    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | 0.28      |\n",
      "|    value_loss         | 0.203     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 86.8      |\n",
      "|    ep_rew_mean        | 86.8      |\n",
      "| time/                 |           |\n",
      "|    fps                | 454       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.442    |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | 0.085     |\n",
      "|    value_loss         | 0.101     |\n",
      "-------------------------------------\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\n    Cannot import pyglet.\n    HINT: you can install pyglet directly via 'pip install pyglet'.\n    But if you really just want to install all Gym dependencies and not have to think about it,\n    'pip install -e .[all]' or 'pip install gym[all]' will do it.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/MSIAM_courses/coding_homeworks/.venv/lib/python3.8/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyglet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2989/4208770330.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MSIAM_courses/coding_homeworks/.venv/lib/python3.8/site-packages/gym/core.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MSIAM_courses/coding_homeworks/.venv/lib/python3.8/site-packages/gym/envs/classic_control/cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/MSIAM_courses/coding_homeworks/.venv/lib/python3.8/site-packages/gym/envs/classic_control/rendering.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \"\"\"\n\u001b[1;32m     19\u001b[0m     \u001b[0mCannot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: \n    Cannot import pyglet.\n    HINT: you can install pyglet directly via 'pip install pyglet'.\n    But if you really just want to install all Gym dependencies and not have to think about it,\n    'pip install -e .[all]' or 'pip install gym[all]' will do it.\n    "
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2450956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also possible to train the model with a one liner\n",
    "model = A2C('MlpPolicy', 'CartPole-v1').learn(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75111d",
   "metadata": {},
   "source": [
    "# Create custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d03bf82",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2842802784.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_2989/2842802784.py\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    def __init__(self, arg1, arg2, ...):\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from gym import spaces\n",
    "\n",
    "class CustomEnv(gym.Env):\n",
    "    \"\"\"Custom Environment that follows gym interface\"\"\"\n",
    "    \n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self, arg1, arg2, ...):\n",
    "        super(CustomEnv, self).__init__()\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions:\n",
    "        self.action_space = spaces.Discrete(N_DISCRETE_ACTIONS)\n",
    "        \n",
    "        # Example for using image as input:\n",
    "        self.observation_space = space.Box(low=0, high=255, \n",
    "                                           shape=(HEIGHT, WIDTH, N_CHANNELS), dtype=np.uint8)\n",
    "        \n",
    "        def step(self, action: Any):\n",
    "            ...\n",
    "            return observation, reward, done, info\n",
    "        \n",
    "        def reset(self):\n",
    "            self.episode_idx += 1\n",
    "            return observation # reward, done, info can't be included\n",
    "        \n",
    "        def render(self, mode='human'):\n",
    "            ...\n",
    "        def close(self):\n",
    "            ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7b72d5",
   "metadata": {},
   "source": [
    "Then we can define and train a RL agent with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b8f46d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CustomEnv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2989/3258317867.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# The method check_env, verifies that the environment is properly instantiated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Needs to be reviewed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcheck_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CustomEnv' is not defined"
     ]
    }
   ],
   "source": [
    "env = CustomEnv(arg1, ...)\n",
    "# The method check_env, verifies that the environment is properly instantiated\n",
    "# Needs to be reviewed\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2fd88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10000.,  -5000.,      0.,   5000.,  10000.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.linspace(-10000, 10000, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e02233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gym import spaces\n",
    "spaces.Discrete(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7b6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
